{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827135d3-8071-4403-bdf0-4c5b79c63902",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5455f-23d8-40b0-88b2-df97034a2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from PriceFetcher import PriceFetcher\n",
    "from MarketCorrections import MarketCorrections\n",
    "from Utilities import period_max_drawdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495b33-7a06-47e6-8ee0-97648ae2821b",
   "metadata": {},
   "source": [
    "## Importing Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b9624-dc7a-471f-926d-4d3bc1f5d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pf = PriceFetcher(assets=[\"SPY\", \"HYG\"])\n",
    "# pf.fetch()\n",
    "# df_px = pf.prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86e418-f489-4644-b076-a3ac3533ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spy = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"spy\")\n",
    "df_agg = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"agg\")\n",
    "df_hyg = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"hyg\")\n",
    "df_tlt = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"tlt\")\n",
    "df_gld = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"gld\")\n",
    "df_buffer_010 = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"mqu1bslq\")\n",
    "df_buffer_020 = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"mquslblr\")\n",
    "df_buffer_100 = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"mqu1pplr\")\n",
    "df_sv_hedged_income = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"sv_hedged_income\")\n",
    "df_sv_hedged_balanced = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"sv_hedged_balanced\")\n",
    "df_sv_hedged_enhanced_growth = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"sv_hedged_enhanced_growth\")\n",
    "df_sv_equity_buffer = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"sv_equity_buffer\")\n",
    "df_sv_equity_buffer_growth = pd.read_excel(\"data/bufr_bufd_mquslblr.xlsx\", \"sv_equity_buffer_growth\")\n",
    "\n",
    "df_px = (\n",
    "    df_buffer_100\n",
    "        .merge(df_buffer_010, how=\"left\", on=\"date\")\n",
    "        .merge(df_buffer_020, how=\"left\", on=\"date\")\n",
    "        .merge(df_spy, how=\"left\", on=\"date\")\n",
    "        .merge(df_agg, how=\"left\", on=\"date\")\n",
    "        .merge(df_hyg, how=\"left\", on=\"date\")\n",
    "        .merge(df_tlt, how=\"left\", on=\"date\")\n",
    "        .merge(df_gld, how=\"left\", on=\"date\")\n",
    "        .merge(df_sv_hedged_income, how=\"left\", on=\"date\")\n",
    "        .merge(df_sv_hedged_balanced, how=\"left\", on=\"date\")\n",
    "        .merge(df_sv_hedged_enhanced_growth, how=\"left\", on=\"date\")\n",
    "        .merge(df_sv_equity_buffer, how=\"left\", on=\"date\")\n",
    "        .merge(df_sv_equity_buffer_growth, how=\"left\", on=\"date\")\n",
    ")\n",
    "df_px.rename(columns={\"mqu1pplr\":\"buffer_100\", \"mquslblr\":\"buffer_020\", \"mqu1bslq\":\"buffer_010\"}, inplace=True)\n",
    "df_px = df_px.query(\"'2007-04-11' <= date & date <= '2024-12-31'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206e5a5-2774-44eb-8d74-7bc1b0a1125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_px.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c124aa-3092-4bde-be5c-4b7b4ed12fd6",
   "metadata": {},
   "source": [
    "## Defining Market Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc37d2-1edc-4b21-9d1a-998d155ac073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "mc = MarketCorrections(asset=\"SPY\", correction=-0.05)\n",
    "df_corrections = mc.corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9743959-4443-405b-bcf1-71edc6bc62e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   start         33 non-null     object \n",
      " 1   end           33 non-null     object \n",
      " 2   bottom        33 non-null     object \n",
      " 3   drawdown_spy  33 non-null     float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_corrections.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869aaf96-3a74-47e4-839f-179b8dcc584d",
   "metadata": {},
   "source": [
    "## Defining Backtest Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ec5a7-258e-4aa7-9365-3e11c2c27f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedWeightBacktester:\n",
    "    \"\"\"\n",
    "    A backtester for a weighted portfolio of assets with daily rebalancing of the weights.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    portfolio: dict[str, float]\n",
    "        Defines the assets and weights in the portfolio.\n",
    "        \n",
    "    prices: pd.DataFrame\n",
    "        Contains the prices of assets as far back as there is data for in Yahoo Finance.\n",
    "        This is typically the result of the PriceFetcher.fetch() method.\n",
    "        \n",
    "    market_corrections: pd.DataFrame\n",
    "        Contains the start, bottom, end date of prices corrections of a particular asset.\n",
    "        Typically some kind of broad market index like SPY will be used.  This is usually\n",
    "        the result of the MarketCorrections class.  It is modified by the calc_period_drawdown\n",
    "        method to contain the drawdowns of the weighted portfolio during the drawdown periods.\n",
    "        \n",
    "    date_start: datetime.date\n",
    "        The start date of the backtest.\n",
    "        \n",
    "    date_end: datetime.date\n",
    "        The end date of the backtest.\n",
    "\n",
    "    assets: list[str]\n",
    "        The component assets in the portfolio of the backtest.  This is extracted from the portfolio.\n",
    "    \n",
    "    weights: list[str]\n",
    "        The weights of the component assets in the portfolio.  This is extracted from the portfolio\n",
    "\n",
    "    returns: pd.DataFrame\n",
    "        The prices, daily returns, equity curve, drawdowns of the assets\n",
    "        and the weighted portfolio that is being backtested.\n",
    "\n",
    "    cumulative_returns: dict[str, float]\n",
    "        The cumulative returns for each of the component assets and the weighted portfolio.\n",
    "\n",
    "    annual_returns: dict[str, float]\n",
    "        The annualized returns for each of the component assets and the weighted portfolio.\n",
    "\n",
    "    volatility: dict[str, float]\n",
    "        The annualized volatility for each of the component assets and the weighted portfolio.\n",
    "\n",
    "    sharpe_ratio: dict[str, float]\n",
    "        The annualized sharpe-ratio for each of the component assets and the weighted portfolio.\n",
    "\n",
    "    sharpe_ratio: dict[str, float]\n",
    "        The annualized sharpe-ratio for each of the component assets and the weighted portfolio.\n",
    "\n",
    "    drawdown_max: dict[str, float]\n",
    "        The maximum for each of the component assets and the weighted portfolio.\n",
    "\n",
    "    annual_performance: pd.DataFrame\n",
    "        The performance of the weighted portfolio for each calendar year in the backtest.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 portfolio: dict[str, float], \n",
    "                 prices: pd.DataFrame,\n",
    "                 market_corrections: pd.DataFrame,\n",
    "                 date_start: datetime.date,\n",
    "                 date_end: datetime.date,\n",
    "                 frequency_rebalance: str):\n",
    "        self.portfolio = portfolio\n",
    "        self.prices = prices        \n",
    "        self.market_corrections = (\n",
    "            market_corrections\n",
    "                .query(\"@date_start <= start & end <= @date_end\").copy()\n",
    "        )\n",
    "        \"\"\"\n",
    "        portfolio: dict[str, float]\n",
    "            Defines the assets and weights in the portfolio.\n",
    "            \n",
    "        prices: pd.DataFrame\n",
    "            Contains the prices of assets as far back as there is data for in Yahoo Finance.\n",
    "            This is typically the result of the PriceFetcher.fetch() method.\n",
    "            \n",
    "        market_corrections: pd.DataFrame\n",
    "            Contains the start, bottom, end date of prices corrections of a particular asset.\n",
    "            Typically some kind of broad market index like SPY will be used.  This is usually\n",
    "            the result of the MarketCorrections class.  It is modified by the calc_period_drawdown\n",
    "            method to contain the drawdowns of the weighted portfolio during the drawdown periods.\n",
    "            \n",
    "        date_start: datetime.date\n",
    "            The start date of the backtest.\n",
    "            \n",
    "        date_end: datetime.date\n",
    "            The end date of the backtest.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.date_start = date_start\n",
    "        self.date_end = date_end\n",
    "        self.frequency_rebalance = frequency_rebalance\n",
    "\n",
    "        # isolating weights and assets from portfolio\n",
    "        self.assets = []\n",
    "        self.weights = []\n",
    "        for asset, weight in self.portfolio.items():\n",
    "            self.assets.append(asset)\n",
    "            self.weights.append(weight)\n",
    "\n",
    "\n",
    "\n",
    "    def calc_daily_returns(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculates the prices, daily returns, equity curve, drawdowns of the assets\n",
    "        and the weighted portfolio that is being backtested.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.returns = self.prices.query(\"@date_start <= date & date <= @date_end\").copy().reset_index(drop=True)\n",
    "\n",
    "        # calculating component asset daily returns\n",
    "        for ix_asset in self.assets:\n",
    "            ret_col_name = \"ret_\" + ix_asset\n",
    "            self.returns[ret_col_name] = self.returns[ix_asset].pct_change()\n",
    "        self.returns.fillna(0, inplace=True)\n",
    "\n",
    "        # calculating portfolio daily returns\n",
    "        if self.frequency_rebalance == None:\n",
    "            cols = []\n",
    "            for ix_asset in self.assets:\n",
    "                cols.append(\"ret_\" + ix_asset)\n",
    "            self.returns[\"ret_portfolio\"] =  np.sum(np.array(self.returns[cols]) * self.weights, axis=1)\n",
    "        else:\n",
    "            self.calc_rebalanced_portfolio()\n",
    "\n",
    "        # calculating equity curve for components and portfolio\n",
    "        for ix_asset in self.assets:\n",
    "            ret_col_name = \"ret_\" + ix_asset\n",
    "            equity_col_name = \"equity_\" + ix_asset\n",
    "            self.returns[equity_col_name] = (1 + self.returns[ret_col_name]).cumprod()\n",
    "        self.returns[\"equity_portfolio\"] = (1 + self.returns[\"ret_portfolio\"]).cumprod()\n",
    "\n",
    "        # calculating drawdowns for components and portfolio\n",
    "        for ix_asset in self.assets:\n",
    "            equity_col_name = \"equity_\" + ix_asset\n",
    "            drawdown_col_name = \"drawdown_\" + ix_asset\n",
    "            self.returns[drawdown_col_name] = (self.returns[equity_col_name] / self.returns[equity_col_name].cummax()) - 1\n",
    "        self.returns[\"drawdown_portfolio\"] = (self.returns[\"equity_portfolio\"] / self.returns[\"equity_portfolio\"].cummax()) - 1\n",
    "\n",
    "\n",
    "    def calc_rebalanced_portfolio(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculates the daily returns of a rebalanced portfolio.\n",
    "        \"\"\"\n",
    "        df = self.returns[[\"date\"]].copy()\n",
    "    \n",
    "        # determining rebalance dates\n",
    "        if self.frequency_rebalance == \"annual\":\n",
    "            self.returns[\"year\"] = self.returns[\"date\"].dt.year\n",
    "            df[\"year\"] = df[\"date\"].dt.year\n",
    "            df_date_rebalance = df.groupby([\"year\"])[[\"date\"]].max().reset_index()\n",
    "            df_date_rebalance.rename(columns={\"date\":\"date_rebalance\"}, inplace=True)\n",
    "            self.returns = self.returns.merge(df_date_rebalance, how=\"left\", on=[\"year\"])\n",
    "        elif self.frequency_rebalance == \"semiannual\":\n",
    "            self.returns[\"year\"] = self.returns[\"date\"].dt.year\n",
    "            self.returns[\"month\"] = self.returns[\"date\"].dt.month\n",
    "            self.returns[\"half\"] = np.where(self.returns[\"month\"] <= 6, 1, 2)\n",
    "            df[\"year\"] = df[\"date\"].dt.year\n",
    "            df[\"month\"] = df[\"date\"].dt.month\n",
    "            df[\"half\"] = np.where(df[\"month\"] <= 6, 1, 2)\n",
    "            df_date_rebalance = df.groupby([\"year\",\"half\"])[[\"date\"]].max().reset_index()\n",
    "            df_date_rebalance.rename(columns={\"date\":\"date_rebalance\"}, inplace=True)\n",
    "            self.returns = self.returns.merge(df_date_rebalance, how=\"left\", on=[\"year\", \"half\"])\n",
    "        elif self.frequency_rebalance == \"quarterly\":\n",
    "            self.returns[\"year\"] = self.returns[\"date\"].dt.year\n",
    "            self.returns[\"quarter\"] = self.returns[\"date\"].dt.quarter\n",
    "            df[\"year\"] = df[\"date\"].dt.year\n",
    "            df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "            df_date_rebalance = df.groupby([\"year\",\"quarter\"])[[\"date\"]].max().reset_index()\n",
    "            df_date_rebalance.rename(columns={\"date\":\"date_rebalance\"}, inplace=True)\n",
    "            self.returns = self.returns.merge(df_date_rebalance, how=\"left\", on=[\"year\", \"quarter\"])\n",
    "        elif self.frequency_rebalance == \"monthly\":\n",
    "            self.returns[\"year\"] = self.returns[\"date\"].dt.year\n",
    "            self.returns[\"month\"] = self.returns[\"date\"].dt.month\n",
    "            df[\"year\"] = df[\"date\"].dt.year\n",
    "            df[\"month\"] = df[\"date\"].dt.month\n",
    "            df_date_rebalance = df.groupby([\"year\",\"month\"])[[\"date\"]].max().reset_index()\n",
    "            df_date_rebalance.rename(columns={\"date\":\"date_rebalance\"}, inplace=True)\n",
    "            self.returns = self.returns.merge(df_date_rebalance, how=\"left\", on=[\"year\", \"month\"])\n",
    "        elif self.frequency_rebalance == \"daily\":\n",
    "            self.returns[\"date_rebalance\"] = self.returns[\"date\"]\n",
    "    \n",
    "        # initializing values for iteration through self.returns\n",
    "        before_rebal = {}\n",
    "        lst_total_value = []\n",
    "        total_value = 0\n",
    "        for ix_asset in self.assets:\n",
    "            before_rebal[ix_asset] = [self.portfolio[ix_asset]]\n",
    "            total_value += before_rebal[ix_asset][-1]\n",
    "        lst_total_value.append(total_value)\n",
    "        after_rebal = {}\n",
    "        for ix_asset in self.assets:\n",
    "            after_rebal[ix_asset] = [self.portfolio[ix_asset]]\n",
    "    \n",
    "        # iterating through self.returns to calculate portfolio values\n",
    "        for _ , row in self.returns[1:].iterrows():\n",
    "            # calculating end-of-day value of each asset allocation\n",
    "            for ix_asset, _ in before_rebal.items():\n",
    "                before_rebal[ix_asset].append(after_rebal[ix_asset][-1] * (1 + row[\"ret_\"+ ix_asset]))\n",
    "            \n",
    "            # calculating total portfolio value\n",
    "            total_value = 0\n",
    "            for ix_asset, _ in before_rebal.items():\n",
    "                total_value += before_rebal[ix_asset][-1]\n",
    "            lst_total_value.append(total_value)    \n",
    "        \n",
    "            # rebalancing if needed\n",
    "            if row[\"date\"] == row[\"date_rebalance\"]:\n",
    "                for ix_asset, _ in after_rebal.items():\n",
    "                    after_rebal[ix_asset].append(total_value * self.portfolio[ix_asset])\n",
    "            else:\n",
    "                for ix_asset, _ in after_rebal.items():\n",
    "                    after_rebal[ix_asset].append(before_rebal[ix_asset][-1])\n",
    "    \n",
    "        # adding columns to self.returns\n",
    "        df_before_rebal = pd.DataFrame(before_rebal)\n",
    "        for ix_asset, _ in before_rebal.items():\n",
    "            df_before_rebal.rename(columns={ix_asset: \"before_rebal_\" + ix_asset}, inplace=True)\n",
    "        df_before_rebal\n",
    "        df_after_rebal = pd.DataFrame(after_rebal)\n",
    "        for ix_asset, _ in after_rebal.items():\n",
    "            df_after_rebal.rename(columns={ix_asset: \"after_rebal_\" + ix_asset}, inplace=True)\n",
    "        df_after_rebal\n",
    "        df_total_value = pd.DataFrame({\"portfolio_total_value\":lst_total_value})\n",
    "        self.returns = pd.concat([self.returns, df_before_rebal, df_total_value, df_after_rebal], axis=1)\n",
    "        self.returns[\"ret_portfolio\"] = self.returns[\"portfolio_total_value\"].pct_change()\n",
    "        self.returns.fillna(0, inplace=True)\n",
    "\n",
    "    \n",
    "    def calc_portfolio_statistics(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculates the portfolio statistics and annual performance of the component assets\n",
    "        and the weighted portfolio being backtested.\n",
    "        \"\"\"\n",
    "        # cumulative return\n",
    "        self.cumulative_return = {}\n",
    "        for ix_asset in self.assets:\n",
    "            equity_col_name = \"equity_\" + ix_asset\n",
    "            self.cumulative_return[ix_asset] = (self.returns[equity_col_name].iloc[-1] - 1)\n",
    "        self.cumulative_return[\"portfolio\"] = self.returns[\"equity_portfolio\"].iloc[-1] - 1\n",
    "        \n",
    "        # annual return\n",
    "        self.annual_return = {}\n",
    "        for ix_asset in self.assets:\n",
    "            equity_col_name = \"equity_\" + ix_asset\n",
    "            self.annual_return[ix_asset] = (self.returns[equity_col_name].iloc[-1] ** (252/(len(self.returns) - 1)) - 1)\n",
    "        self.annual_return[\"portfolio\"] = self.returns[\"equity_portfolio\"].iloc[-1] ** (252/(len(self.returns) - 1)) - 1\n",
    "\n",
    "        # volatility\n",
    "        self.volatility = {}\n",
    "        for ix_asset in self.assets:\n",
    "            ret_col_name = \"ret_\" + ix_asset\n",
    "            self.volatility[ix_asset] = self.returns[ret_col_name][1:].std() * np.sqrt(252)\n",
    "        self.volatility[\"portfolio\"] = self.returns[\"ret_portfolio\"][1:].std() * np.sqrt(252)\n",
    "\n",
    "        # sharpe-ratio\n",
    "        self.sharpe_ratio = {}\n",
    "        for ix_asset in self.assets:\n",
    "            ret_col_name = \"ret_\" + ix_asset\n",
    "            self.sharpe_ratio[ix_asset] = (self.returns[ret_col_name][1:].mean() / self.returns[ret_col_name][1:].std()) * np.sqrt(252)\n",
    "        self.sharpe_ratio[\"portfolio\"] = (self.returns[\"ret_portfolio\"][1:].mean() / self.returns[\"ret_portfolio\"][1:].std()) * np.sqrt(252)\n",
    "        \n",
    "        # maximum drawdown\n",
    "        self.drawdown_max = {}\n",
    "        for ix_asset in self.assets:\n",
    "            drawdown_col_name = \"drawdown_\" + ix_asset\n",
    "            self.drawdown_max[ix_asset] = self.returns[drawdown_col_name].min()\n",
    "        self.drawdown_max[\"portfolio\"] =  self.returns[\"drawdown_portfolio\"].min()\n",
    "        \n",
    "        # annual performance\n",
    "        df_portfolio = self.returns[[\"date\", \"ret_portfolio\"]].copy()\n",
    "        df_portfolio[\"date\"] = pd.to_datetime(df_portfolio[\"date\"])\n",
    "        df_portfolio[\"year\"] = df_portfolio[\"date\"].dt.year\n",
    "        self.annual_performance = df_portfolio.groupby([\"year\"])[[\"ret_portfolio\"]].agg(lambda x: np.prod(1 + x) - 1).reset_index()\n",
    "\n",
    "    def calc_period_drawdowns(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculates the performance of the weighted portfolio during the drawdown periods.\n",
    "        \"\"\"\n",
    "        drawdowns_portfolio = []\n",
    "        for ix in self.market_corrections.index:\n",
    "            dt_start = self.market_corrections.at[ix, \"start\"]\n",
    "            dt_end = self.market_corrections.at[ix, \"end\"]\n",
    "            drawdown_portfolio = period_max_drawdown(asset=\"portfolio\", date_start=dt_start, date_end=dt_end, df_ret=self.returns)\n",
    "            drawdowns_portfolio.append(drawdown_portfolio)\n",
    "        self.market_corrections[\"drawdown_portfolio\"] = drawdowns_portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63747d8-1916-4450-8b2a-ac2158f76f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = {\n",
    "    \"spy\":0.5,\n",
    "    \"hyg\":0.5\n",
    "}\n",
    "# portfolio = {\n",
    "#     \"spy\": 0.45,\n",
    "#     \"agg\": 0.1,\n",
    "#     \"tlt\": 0.2,\n",
    "#     \"buffer_010\": 0.1,\n",
    "#     \"buffer_020\": 0.1,\n",
    "#     \"buffer_100\": 0.05,\n",
    "# }\n",
    "date_start = datetime.date(2007, 4, 11)\n",
    "date_end = datetime.date(2024, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebd97b-d8fd-4007-a126-8ec66c707a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drb = FixedWeightBacktester(portfolio, df_px, df_corrections, date_start, date_end, None)\n",
    "drb.calc_daily_returns()\n",
    "drb.calc_portfolio_statistics()\n",
    "drb.calc_period_drawdowns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4f46d-1c62-4016-9c89-39999da81c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spy': 4.698201111828501, 'hyg': 1.2849774775552096, 'portfolio': 2.7857792474375533}\n",
      "{'spy': 0.10326982171084764, 'hyg': 0.04777623619061333, 'portfolio': 0.07808357049579095}\n",
      "{'spy': 0.19866942398323126, 'hyg': 0.11237631679457355, 'portfolio': 0.14362456326670317}\n",
      "{'spy': 0.5942315261922044, 'hyg': 0.471367186926365, 'portfolio': 0.5953930840795643}\n",
      "{'spy': -0.5518944290604038, 'hyg': -0.3424653847240299, 'portfolio': -0.4419575389552498}\n"
     ]
    }
   ],
   "source": [
    "print(drb.cumulative_return)\n",
    "print(drb.annual_return)\n",
    "print(drb.volatility)\n",
    "print(drb.sharpe_ratio)\n",
    "print(drb.drawdown_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4767be-be24-4ccd-8f8d-2f1ee3418491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drb = FixedWeightBacktester(portfolio, df_px, df_corrections, date_start, date_end, None)\n",
    "# drb.calc_daily_returns()\n",
    "# drb.calc_portfolio_statistics()\n",
    "# drb.calc_period_drawdowns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd1afa-9138-4795-a243-60e8bf17129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(drb.cumulative_return)\n",
    "# print(drb.annual_return)\n",
    "# print(drb.volatility)\n",
    "# print(drb.sharpe_ratio)\n",
    "# print(drb.drawdown_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86390e-3df1-492b-ae58-5911f426ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(drb.portfolio)\n",
    "# print(drb.assets)\n",
    "# print(drb.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d29865-194e-47c4-b73f-6a2ef1ed8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drb.prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1a1b1-6318-49f5-9887-cd07fea044ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drb.market_corrections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1ffdc-2772-4e1b-97c6-b0d347d747fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drb.returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1561222-86cf-44c3-960c-ada2dc73f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drb.annual_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26e8b4-0f92-4395-8928-91582164bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drb.market_corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a765ab-4e1d-4ee8-b6c9-62a76cf9e9be",
   "metadata": {},
   "source": [
    "## OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d07fff-402e-4054-8566-46b9b19d6851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_market_data(self):\n",
    "#     # getting asset prices\n",
    "#     pf = PriceFetcher(assets=[x.upper() for x in self.assets])\n",
    "#     pf.fetch()\n",
    "#     self.prices = pf.prices\n",
    "#     pf = None\n",
    "\n",
    "#     # getting market corrections\n",
    "#     mc = MarketCorrections(\n",
    "#         asset=self.reference_market.upper(),\n",
    "#         correction=self.correction_size,\n",
    "#     )\n",
    "#     self.market_corrections = \\\n",
    "#         mc.corrections.query(\"@self.date_start <= start & end <= @self.date_end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
